{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crsp = pd.read_pickle(\"Data/crsp.pkl\")\n",
    "price = pd.read_pickle('Data/price.pkl')\n",
    "dividends = pd.read_pickle('Data/dividends.pkl')\n",
    "bookvalue = pd.read_pickle('Data/bookvalue.pkl')\n",
    "shrout = pd.read_pickle('Data/shrout.pkl')\n",
    "bm_dec = pd.read_pickle('Data/bm_dec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_dec.index = pd.to_datetime(bm_dec.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is year:  1961\n",
      "This is year (bottom):  1961\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    I need a dataframe which comprises returns of each position in the portfolio, every year\n",
    "\n",
    "    Challenge is now to get structure right. all stocks of portfolio for every year in one df‚\n",
    "\n",
    "\"\"\"\n",
    "price_minus_long_monthly = []\n",
    "price_minus_short_monthly = []\n",
    "\n",
    "dividends_m_long_monthly = []\n",
    "dividends_m_short_monthly = []\n",
    "\n",
    "price_long_monthly = []\n",
    "price_short_monthly = []\n",
    "\n",
    "bottom_permnos = []\n",
    "top_permnos = []\n",
    "\n",
    "for year in sorted(set(date.year for date in bm_dec.index)):\n",
    "     \n",
    "    date = pd.Timestamp(f\"{year}-06\")\n",
    "    date_dec = pd.Timestamp(f\"{year-1}-12\")\n",
    "    if date_dec not in bm_dec.index:\n",
    "        continue\n",
    "    if year == 2018:\n",
    "        continue\n",
    "    # Timeframe: July-June\n",
    "    month_range = pd.date_range(start=date + pd.DateOffset(months=1), periods=12, freq=\"ME\")\n",
    "    month_range = month_range.to_period('M')\n",
    "\n",
    "    target_date = f\"{year}-06\" \n",
    "    top_date = pd.to_datetime(target_date)\n",
    "    crsp['date'] = pd.to_datetime(crsp['date'])\n",
    "\n",
    "    #Top Permnos\n",
    "    if len(top_permnos) == 0:\n",
    "        print(\"This is year: \", year) #Dummy\n",
    "    else:\n",
    "        for m in month_range:\n",
    "            #Computations for monthly returns\n",
    "            date = m.to_timestamp()\n",
    "            shrout_filtered_m_long_monthly = crsp[(crsp['date'] == date) & (crsp['permno'].isin(top_permnos))]\n",
    "            shrout_series_m_long_monthly = shrout_filtered_m_long_monthly.set_index('permno')['adj_shrout']\n",
    "            top_m_prc_monthly = price.loc[date, price.columns.intersection(top_permnos)].dropna()\n",
    "            sharesoutstanding_long_m_prc = shrout_series_m_long_monthly.reindex(top_m_prc_monthly.index) *1000\n",
    "            long_m_prc_monthly = top_m_prc_monthly * sharesoutstanding_long_m_prc\n",
    "            for permno in long_m_prc_monthly:\n",
    "                price_minus_long_monthly.append({'date': date, 'avg_value': long_m_prc_monthly})\n",
    "\n",
    "            #Dividends\n",
    "            top_m_div = dividends.loc[date, dividends.columns.intersection(top_permnos)].dropna()\n",
    "            sharesoutstanding_long_m_div = shrout_series_m_long_monthly.reindex(top_m_div.index) *1000\n",
    "            long_m_div = top_m_div * sharesoutstanding_long_m_div\n",
    "            dividends_m_long_monthly.append({\"date\" : date, \"avg_value\" :long_m_div.sum()})\n",
    "\n",
    "        #dividends_m_long_ts.extend(dividends_m_long_monthly)\n",
    "\n",
    "\n",
    "    #Bottom Permnos\n",
    "    if len(bottom_permnos) == 0:\n",
    "        print(\"This is year (bottom): \", year) #Dummy\n",
    "    else:\n",
    "\n",
    "        for m in month_range:\n",
    "            #Computations for monthly returns\n",
    "            date = m.to_timestamp()\n",
    "            shrout_filtered_m_short_monthly = crsp[(crsp['date'] == date) & (crsp['permno'].isin(bottom_permnos))]\n",
    "            shrout_series_m_short_monthly = shrout_filtered_m_short_monthly.set_index('permno')['adj_shrout']\n",
    "            bottom_m_prc_monthly = price.loc[date, price.columns.intersection(bottom_permnos)].dropna()\n",
    "            sharesoutstanding_short_m_prc_monthly = shrout_series_m_short_monthly.reindex(bottom_m_prc_monthly.index) *1000\n",
    "            short_m_prc_monthly = bottom_m_prc_monthly * sharesoutstanding_short_m_prc_monthly\n",
    "            price_minus_short_monthly.append({'date': date, 'avg_value': short_m_prc_monthly.sum()})\n",
    "\n",
    "            #Dividends\n",
    "            bottom_m_div = dividends.loc[date, dividends.columns.intersection(bottom_permnos)].dropna()\n",
    "            sharesoutstanding_short_m_div = shrout_series_m_short_monthly.reindex(bottom_m_div.index) *1000\n",
    "            short_m_div = bottom_m_div * sharesoutstanding_short_m_div\n",
    "            dividends_m_short_monthly.append({\"date\" : date, \"avg_value\" :short_m_div.sum()})\n",
    "\n",
    "    \"\"\"\"\n",
    "        Stock Selection:\n",
    "\n",
    "        All Stocks in the available Dataset are being sorted in a descending order by Book-to-market ratio.\n",
    "\n",
    "        \"Clean Row\" accesses the DataFrame bm_dec, which contains the book-to-market ratios in wide-format. \n",
    "        Therefore the length of a row is equal to the number of available stocks. Since the only condition for a stock\n",
    "        to be picked is that it is listed at the day of the portfolio selection, there is no look-ahead bias.\n",
    "\n",
    "        The top 30% of stocks are being selected for the long-positions, the bottom 30% for the short-positions, respectively.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #Only stocks which contain values for June of a year get selected. Later months are not considered -> no look-ahead bias\n",
    "    clean_row = bm_dec.loc[date_dec].dropna().sort_values(ascending=False) \n",
    "    n = len(clean_row)\n",
    "    if n == 0:\n",
    "        continue\n",
    "\n",
    "    k = int(n * 0.3)\n",
    "    bottom_permnos = clean_row.iloc[:k].index.tolist() #Selects permnos with the lower B/M-ratios\n",
    "    top_permnos = clean_row.iloc[-k:].index.tolist() #Selects permnos with the higher B/M-ratios\n",
    "\n",
    "    for m in month_range:\n",
    "        #Computations for monthly returns\n",
    "        date = m.to_timestamp()\n",
    "        #Short-Positions\n",
    "        shrout_filtered_short_monthly = crsp[(crsp['date'] == date) & (crsp['permno'].isin(bottom_permnos))]\n",
    "        shrout_series_short_monthly = shrout_filtered_short_monthly.set_index('permno')['adj_shrout']\n",
    "        bottom_prc_monthly = price.loc[date, price.columns.intersection(bottom_permnos)].dropna()\n",
    "        sharesoutstanding_short_prc_monthly = shrout_series_short_monthly.reindex(bottom_prc_monthly.index) *1000\n",
    "        short_prc_monthly = bottom_prc_monthly * sharesoutstanding_short_prc_monthly\n",
    "        if short_prc_monthly.notna().any():\n",
    "            price_short_monthly.append({'date': date, 'avg_value': short_prc_monthly.sum()})\n",
    "        else:\n",
    "            print(f\"No valid prices for {date} — skipping.\")\n",
    "        \n",
    "        #Long-Positions\n",
    "        shrout_filtered_long_monthly = crsp[(crsp['date'] == date) & (crsp['permno'].isin(top_permnos))]\n",
    "        shrout_series_long_monthly = shrout_filtered_long_monthly.set_index('permno')['adj_shrout']\n",
    "        top_prc_monthly = price.loc[date, price.columns.intersection(top_permnos)].dropna()\n",
    "        sharesoutstanding_long_prc_monthly = shrout_series_long_monthly.reindex(top_prc_monthly.index) *1000\n",
    "        long_prc_monthly = top_prc_monthly * sharesoutstanding_long_prc_monthly\n",
    "        if long_prc_monthly.notna().any():\n",
    "            price_long_monthly.append({'date': date, 'avg_value': long_prc_monthly.sum()})\n",
    "        else:\n",
    "            print(f\"No valid prices for {date} — skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m series \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_value\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# a pandas Series with permno as index\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_value\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m date\n",
      "File \u001b[0;32m~/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/series.py:1770\u001b[0m, in \u001b[0;36mSeries.reset_index\u001b[0;34m(self, level, drop, name, inplace, allow_duplicates)\u001b[0m\n\u001b[1;32m   1767\u001b[0m             name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\n\u001b[1;32m   1769\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame(name)\n\u001b[0;32m-> 1770\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49mreset_index(\n\u001b[1;32m   1771\u001b[0m         level\u001b[39m=\u001b[39;49mlevel, drop\u001b[39m=\u001b[39;49mdrop, allow_duplicates\u001b[39m=\u001b[39;49mallow_duplicates\n\u001b[1;32m   1772\u001b[0m     )\n\u001b[1;32m   1773\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/frame.py:6417\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6415\u001b[0m     new_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   6416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 6417\u001b[0m     new_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy(deep\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   6418\u001b[0m \u001b[39mif\u001b[39;00m allow_duplicates \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[1;32m   6419\u001b[0m     allow_duplicates \u001b[39m=\u001b[39m validate_bool_kwarg(allow_duplicates, \u001b[39m\"\u001b[39m\u001b[39mallow_duplicates\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6662\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   6663\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcopy\u001b[39m(\u001b[39mself\u001b[39m, deep: bool_t \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m   6664\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6665\u001b[0m \u001b[39m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6666\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6809\u001b[0m \u001b[39m    dtype: int64\u001b[39;00m\n\u001b[1;32m   6810\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6811\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcopy(deep\u001b[39m=\u001b[39;49mdeep)\n\u001b[1;32m   6812\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6813\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(data, axes\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39m__finalize__(\n\u001b[1;32m   6814\u001b[0m         \u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcopy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6815\u001b[0m     )\n",
      "File \u001b[0;32m~/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m--> 593\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mcopy\u001b[39;49m\u001b[39m\"\u001b[39;49m, deep\u001b[39m=\u001b[39;49mdeep)\n\u001b[1;32m    594\u001b[0m res\u001b[39m.\u001b[39maxes \u001b[39m=\u001b[39m new_axes\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[39m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m~/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:364\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 364\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nested_list = price_minus_long_monthly\n",
    "\n",
    "# Convert each dictionary to a DataFrame\n",
    "df_list = []\n",
    "\n",
    "for entry in nested_list:\n",
    "    date = entry['date']\n",
    "    series = entry['avg_value']  # a pandas Series with permno as index\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = series.reset_index()\n",
    "    df.columns = ['permno', 'avg_value']\n",
    "    df['date'] = date\n",
    "    \n",
    "    df_list.append(df)\n",
    "\n",
    "# Now concatenate the list of DataFrames\n",
    "long_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Set multi-index\n",
    "long_df.set_index(['date', 'permno'], inplace=True)\n",
    "long_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
