{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x105231330>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "long_short_returns = pd.read_pickle(\"long_short_returns.pkl\")\n",
    "ls_returns = pd.DataFrame(long_short_returns)\n",
    "interest_rates = pd.read_csv(\"FEDFUNDS.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "gdp = pd.read_csv(\"GDPC1.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "vix = pd.read_csv(\"VIXCLS.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "cpi = pd.read_csv(\"FPCPITOTLZGUSA.csv\", parse_dates=[\"observation_date\"], index_col=\"observation_date\")\n",
    "consumer_sentiment = pd.read_csv(\"UMCSENT.csv\", parse_dates=[\"observation_date\"], index_col=\"observation_date\")\n",
    "credit_spread = pd.read_csv(\"BAA10Y.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "TB = pd.read_csv(\"DTB3.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "LGB = pd.read_csv(\"IRLTLT01USQ156N.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "industrial_production = pd.read_csv(\"INDPRO.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "consumption = pd.read_csv(\"PCE.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "oil_prices = pd.read_csv(\"WPU0561.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "baa = pd.read_csv(\"BAA.csv\", parse_dates=['observation_date'], index_col='observation_date')\n",
    "\n",
    "\n",
    "\n",
    "interest_rates.rename(columns={\"FEDFUNDS\": \"Interest_Rate\"}, inplace=True)\n",
    "gdp.rename(columns={\"GDPC1\": \"Growth\"}, inplace=True)\n",
    "vix.rename(columns={\"VIXCLS\": \"VIX\"}, inplace=True)\n",
    "cpi.rename(columns={\"FPCPITOTLZGUSA\": \"Inflation\"}, inplace=True)\n",
    "#cpi = inflation_yearly.resample('M').ffill()\n",
    "consumer_sentiment.rename(columns={\"UMCSENT\" : \"Consumer_Sentiment\"}, inplace=True)\n",
    "credit_spread.rename(columns={\"BAA10Y\" : \"Credit_Spread\"}, inplace=True)\n",
    "TB.rename(columns={\"DTB3\" : \"Treasury Bill\"}, inplace=True)\n",
    "LGB.rename(columns={\"IRLTLT01USQ156N\" : \"LGB\"}, inplace=True)\n",
    "industrial_production.rename(columns={\"INDPRO\" : \"Industrial_Production\"}, inplace=True)\n",
    "consumption.rename(columns={\"PCE\" : \"Consumption\"}, inplace=True)\n",
    "oil_prices.rename(columns={\"WPU0561\" : \"Oil_Prices\"}, inplace=True)\n",
    "inflation = np.log(cpi).diff().dropna()\n",
    "\n",
    "\n",
    "def to_month_end(df):\n",
    "    # Wenn PeriodIndex: in Monatsende-DatetimeIndex umwandeln\n",
    "    if isinstance(df.index, pd.PeriodIndex):\n",
    "        df.index = df.index.to_timestamp('M')\n",
    "    else:\n",
    "        df.index = pd.to_datetime(df.index).to_period('M').to_timestamp('M')\n",
    "    return df\n",
    "\n",
    "ls_returns = to_month_end(ls_returns)\n",
    "interest_rates = to_month_end(interest_rates)\n",
    "gdp = to_month_end(gdp)\n",
    "vix = to_month_end(vix)\n",
    "vix = vix.groupby(vix.index).mean()\n",
    "consumer_sentiment = to_month_end(consumer_sentiment)\n",
    "TB = to_month_end(TB)\n",
    "LGB = to_month_end(LGB)\n",
    "industrial_production = to_month_end(industrial_production)\n",
    "consumption = to_month_end(consumption)\n",
    "oil_prices = to_month_end(oil_prices)\n",
    "baa = to_month_end(baa)\n",
    "#inflation = to_month_end(inflation)\n",
    "\n",
    "#Derived Series\n",
    "MP = np.log(industrial_production) - np.log(industrial_production.shift(1))\n",
    "YP = np.log(industrial_production) - np.log(industrial_production.shift(12))\n",
    "RHO = TB.shift(1) - inflation\n",
    "DEI = expected_inflation.shift(-1) - expected_inflation\n",
    "UPR = baa - LGB\n",
    "UTS = LGB - TB.shift(1)\n",
    "\n",
    "# Deine Variablen (MP, YP, etc.) definieren\n",
    "\n",
    "# Indizes ohne Duplikate (wie du schon machst)\n",
    "RHO = RHO[~RHO.index.duplicated(keep='first')]\n",
    "UTS = UTS[~UTS.index.duplicated(keep='first')]\n",
    "\n",
    "# Gemeinsamen Index bestimmen, bei dem keine NaNs auftreten\n",
    "common_index = MP.dropna().index\n",
    "common_index = common_index.intersection(YP.dropna().index)\n",
    "common_index = common_index.intersection(RHO.dropna().index)\n",
    "common_index = common_index.intersection(DEI.dropna().index)\n",
    "common_index = common_index.intersection(UPR.dropna().index)\n",
    "common_index = common_index.intersection(UTS.dropna().index)\n",
    "\n",
    "# Zusammenführen nur auf gemeinsamen Index\n",
    "#macros = pd.concat([df.loc[common_index] for df in [MP, YP, RHO, DEI, UPR, UTS]], axis=1)\n",
    "#macros.columns = ['MP', 'YP', 'RHO', 'DEI', 'UPR', 'UTS']\n",
    "\n",
    "#ls_returns.index = ls_returns.index.to_timestamp()\n",
    "ls_returns.index = pd.to_datetime(ls_returns.index)\n",
    "ls_returns.index = ls_returns.index.normalize()\n",
    "#macros.index = macros.index.normalize()\n",
    "#macros.index = macros.index.to_timestamp()\n",
    "#common_index = ls_returns.index.intersection(macros.index)\n",
    "#ls_returns = ls_returns.loc[common_index]\n",
    "#macros = macros.loc[common_index]\n",
    "#macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inflation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>1.233584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>4.697859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>8.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>4.116338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>2.949525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Inflation\n",
       "observation_date           \n",
       "2020-01-01         1.233584\n",
       "2021-01-01         4.697859\n",
       "2022-01-01         8.002800\n",
       "2023-01-01         4.116338\n",
       "2024-01-01         2.949525"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:              Inflation   No. Observations:                  754\n",
      "Model:                 ARIMA(0, 0, 1)   Log Likelihood                 264.406\n",
      "Date:                Sun, 25 May 2025   AIC                           -522.812\n",
      "Time:                        15:37:39   BIC                           -508.936\n",
      "Sample:                             0   HQIC                          -517.467\n",
      "                                - 754                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -7.664e-06    2.8e-05     -0.274      0.784   -6.25e-05    4.72e-05\n",
      "ma.L1         -0.9998      0.074    -13.601      0.000      -1.144      -0.856\n",
      "sigma2         0.0288      0.002     13.768      0.000       0.025       0.033\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):            533226.93\n",
      "Prob(Q):                              1.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               7.31   Skew:                            -0.54\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                       133.28\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "#Conputing unexpected inflation Part 1\n",
    "\n",
    "# 1. Berechne log Inflation\n",
    "log_cpi = np.log(cpi)\n",
    "pi_t = log_cpi.diff().dropna()  # π_t = log(CPI_t) - log(CPI_{t-1})\n",
    "\n",
    "# 2. Veränderung der Inflation: Δπ_t = π_t - π_{t-1}\n",
    "delta_pi = pi_t.diff().dropna()\n",
    "\n",
    "# 3. MA(1)-Modell auf Δπ_t\n",
    "model = sm.tsa.ARIMA(delta_pi, order=(0, 0, 1))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing unexpected inflaiton part 2\n",
    "theta = results.params['ma.L1']\n",
    "residuals = results.resid\n",
    "\n",
    "# Erwartete Inflation: Et[I_t | t-1] = I_{t-1} - θ * ε_{t-1}\n",
    "expected_inflation = inflation.shift(1) - theta * residuals.shift(1)\n",
    "unexpected_inflation = inflation - expected_inflation\n",
    "expected_inflation = expected_inflation.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "observation_date\n",
       "1960-02-29             NaN\n",
       "1960-03-31   -3.720485e-07\n",
       "1960-04-30   -3.721158e-07\n",
       "1960-05-31   -3.721158e-07\n",
       "1960-06-30   -3.721158e-07\n",
       "                  ...     \n",
       "2023-09-30   -3.721158e-07\n",
       "2023-10-31   -3.721158e-07\n",
       "2023-11-30   -3.721158e-07\n",
       "2023-12-31   -3.721158e-07\n",
       "2024-01-31   -3.721158e-07\n",
       "Length: 755, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 1. CPI log differenzieren\n",
    "inflation = np.log(cpi).diff()\n",
    "\n",
    "# 2. NaNs entfernen\n",
    "inflation_clean = inflation.dropna()\n",
    "\n",
    "# 3. Fit ARIMA(0,0,1)\n",
    "model = sm.tsa.ARIMA(inflation_clean, order=(0,0,1))\n",
    "results = model.fit()\n",
    "\n",
    "theta = results.params['ma.L1']\n",
    "residuals = results.resid\n",
    "\n",
    "# 4. Sicherstellen, dass es Series sind\n",
    "inflation_clean = inflation_clean.squeeze()\n",
    "residuals = residuals.squeeze()\n",
    "\n",
    "# 5. Erwartete Inflation berechnen\n",
    "expected_inflation = inflation_clean.shift(1) - theta * residuals.shift(1)\n",
    "\n",
    "# 6. Ergebnis prüfen\n",
    "expected_inflation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "X = macros\n",
    "#Standardize Data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=X.shape[1])\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"Erklärte Varianz pro Hauptkomponente:\", explained_variance_ratio)\n",
    "print(\"Kumulative erklärte Varianz:\", np.cumsum(explained_variance_ratio))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(range(1, len(explained_variance_ratio)+1), explained_variance_ratio, alpha=0.7, label='Einzelne Varianz')\n",
    "plt.step(range(1, len(explained_variance_ratio)+1), np.cumsum(explained_variance_ratio), where='mid', label='Kumulative Varianz')\n",
    "plt.xlabel('Hauptkomponenten')\n",
    "plt.ylabel('Erklärte Varianz')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "n_components = 1\n",
    "X_pca_reduced = X_pca[:, :n_components]\n",
    "\n",
    "# Optional: DataFrame mit PCs für weitere Analyse\n",
    "X_pca_df = pd.DataFrame(X_pca_reduced, index=X.index, columns=[f'PC{i+1}' for i in range(n_components)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         long_short_ret   R-squared:                       0.029\n",
      "Model:                            GLS   Adj. R-squared:                  0.027\n",
      "Method:                 Least Squares   F-statistic:                     9.747\n",
      "Date:                Sun, 25 May 2025   Prob (F-statistic):           6.71e-05\n",
      "Time:                        12:04:37   Log-Likelihood:                 1567.2\n",
      "No. Observations:                 684   AIC:                            -3128.\n",
      "Df Residuals:                     681   BIC:                            -3115.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.0045      0.002      2.702      0.007       0.001       0.008\n",
      "Inflation        -0.0019      0.000     -4.344      0.000      -0.003      -0.001\n",
      "Interest_Rate     0.0013      0.000      3.751      0.000       0.001       0.002\n",
      "==============================================================================\n",
      "Omnibus:                       53.780   Durbin-Watson:                   1.670\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              259.660\n",
      "Skew:                          -0.034   Prob(JB):                     4.13e-57\n",
      "Kurtosis:                       6.018   Cond. No.                         16.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "#GLS\n",
    "Y = ls_returns\n",
    "#X = macros commented out, due to PCA\n",
    "X = macros\n",
    "X = sm.add_constant(X)\n",
    "X_pca_df = sm.add_constant(X_pca_df)\n",
    "\n",
    "ols_model = sm.OLS(Y, X).fit(cov_type=\"HC3\")\n",
    "residuals = ols_model.resid\n",
    "\n",
    "resid_sq = residuals ** 2 #Squared residuals\n",
    "var_model = sm.OLS(resid_sq, X).fit(cov_type=\"HC3\") #estimating the residuals\n",
    "sigma2_hat = var_model.fittedvalues.clip(lower=1e-8) #avoiding 0\n",
    "\n",
    "sigma = np.diag(sigma2_hat) #constructing Covariance Matrix\n",
    "\n",
    "gls_model = sm.GLS(Y, X, sigma=sigma).fit(cov_type=\"HC3\")\n",
    "print(gls_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature            VIF\n",
      "0          const  106064.470778\n",
      "1  Interest_Rate       2.207133\n",
      "2         Growth       1.659344\n",
      "3            VIX       1.394873\n",
      "4      Inflation       2.254602\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_pca_df = sm.add_constant(X)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_pca_df.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_pca_df.values, i) for i in range(X_pca_df.shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMIMAX Modell - Model Fit\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "X = macros\n",
    "Y = ls_returns\n",
    "#Model fit\n",
    "ar_order = [0,1,2,3,4,5, 6, 7]\n",
    "i_order = [0,1,2,3,4,5]\n",
    "ma_order = [0,1,2,3,4,5]\n",
    "fit = []\n",
    "for p in ar_order:\n",
    "    for d in i_order:\n",
    "        for q in ma_order:\n",
    "            try:\n",
    "                model = SARIMAX(Y, exog=X, order=(p,d,q))  # (p,d,q): AR, differenzieren, MA\n",
    "                model_fit = model.fit()\n",
    "                 #fit.append({\"likelihood\" : model_fit.llf, \"P\": p, \"D\" : d, \"Q\" : q})\n",
    "                fit.append({\"aic\" : model_fit.aic, \"P\": p, \"D\" : d, \"Q\" : q})\n",
    "            except:\n",
    "                continue\n",
    "#best_model = max(fit, key=lambda x: x[\"likelihood\"])\n",
    "\n",
    "best_model = min(fit, key=lambda x: x[\"aic\"])\n",
    "print(\"Bestes Modell:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:         long_short_ret   No. Observations:                  274\n",
      "Model:               SARIMAX(1, 0, 0)   Log Likelihood                 603.057\n",
      "Date:                Fri, 23 May 2025   AIC                          -1196.113\n",
      "Time:                        16:31:59   BIC                          -1178.048\n",
      "Sample:                             0   HQIC                         -1188.862\n",
      "                                - 274                                         \n",
      "Covariance Type:               robust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.0144      0.012      1.242      0.214      -0.008       0.037\n",
      "Inflation        -0.0016      0.002     -0.957      0.339      -0.005       0.002\n",
      "Credit_Spread    -0.0028      0.004     -0.751      0.453      -0.010       0.004\n",
      "ar.L1             0.1664      0.109      1.525      0.127      -0.047       0.380\n",
      "sigma2            0.0007      0.000      7.134      0.000       0.001       0.001\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):               130.39\n",
      "Prob(Q):                              0.95   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.16   Skew:                            -0.01\n",
      "Prob(H) (two-sided):                  0.48   Kurtosis:                         6.38\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Quasi-maximum likelihood covariance matrix used for robustness to some misspecifications; calculated using the observed information matrix (complex-step) described in Harvey (1989).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/justusschenk/Bachelorarbeit/.venv/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "#SARIMAX \n",
    "Y = ls_returns\n",
    "X = macros\n",
    "X = sm.add_constant(X)\n",
    "model = SARIMAX(Y, exog=X, order=(1,0,0))\n",
    "model_fit = model.fit(cov_type=\"robust\")\n",
    "print(model_fit.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all Variance Inflation Factors are well below 10 there is no multicollinearity to be suspected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
